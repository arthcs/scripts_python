FIB: Disabled
I/O completed
num of threads = 52
number of Clusters 5
number of Attributes 34

Time for process: 2.482173
=== FIB ===
FIB - Execution Time: 3.32135 seconds
FIB - Energy: 542.71003500 Joules
FIB - EDP: 1802.52770
Elapsed Time: 3.383s
    SP GFLOPS: 1.803
    DP GFLOPS: 0.000
    x87 GFLOPS: 0.000
    CPI Rate: 7.808
     | The CPI may be too high. This could be caused by issues such as memory
     | stalls, instruction starvation, branch misprediction or long latency
     | instructions. Explore the other hardware-related metrics to identify what
     | is causing high CPI.
     |
    Average CPU Frequency: 2.810 GHz 
    Total Thread Count: 52
Effective Physical Core Utilization: 62.3% (27.422 out of 44)
 | The metric value is low, which may signal a poor physical CPU cores
 | utilization caused by:
 |     - load imbalance
 |     - threading runtime overhead
 |     - contended synchronization
 |     - thread/process underutilization
 |     - incorrect affinity that utilizes logical cores instead of physical
 |       cores
 | Explore sub-metrics to estimate the efficiency of MPI and OpenMP parallelism
 | or run the Locks and Waits analysis to identify parallel bottlenecks for
 | other parallel runtimes.
 |
    Effective Logical Core Utilization: 36.8% (32.368 out of 88)
     | The metric value is low, which may signal a poor logical CPU cores
     | utilization. Consider improving physical core utilization as the first
     | step and then look at opportunities to utilize logical cores, which in
     | some cases can improve processor throughput and overall performance of
     | multi-threaded applications.
     |
Memory Bound: 90.4% of Pipeline Slots
 | The metric value is high. This can indicate that the significant fraction of
 | execution pipeline slots could be stalled due to demand memory load and
 | stores. Use Memory Access analysis to have the metric breakdown by memory
 | hierarchy, memory bandwidth information, correlation by memory objects.
 |
    Cache Bound: 98.7% of Clockticks
     | A significant proportion of cycles are being spent on data fetches from
     | caches. Check Memory Access analysis to see if accesses to L2 or L3
     | caches are problematic and consider applying the same performance tuning
     | as you would for a cache-missing workload. This may include reducing the
     | data working set size, improving data access locality, blocking or
     | partitioning the working set to fit in the lower cache levels, or
     | exploiting hardware prefetchers. Consider using software prefetchers, but
     | note that they can interfere with normal loads, increase latency, and
     | increase pressure on the memory system. This metric includes coherence
     | penalties for shared data. Check Microarchitecture Exploration analysis
     | to see if contested accesses or data sharing are indicated as likely
     | issues.
     |
    DRAM Bound: 0.0% of Clockticks
        DRAM Bandwidth Bound: 0.0% of Elapsed Time
    NUMA: % of Remote Accesses: 0.0%

    Bandwidth Utilization
    Bandwidth Domain             Platform Maximum  Observed Maximum  Average  % of Elapsed Time with High BW Utilization(%)
    ---------------------------  ----------------  ----------------  -------  ---------------------------------------------
    DRAM, GB/sec                 194                         22.800    9.991                                           0.0%
    DRAM Single-Package, GB/sec  97                          22.600    9.435                                           0.0%
    QPI Outgoing, GB/sec         68                          16.600    7.792                                           0.0%
Vectorization: 0.0% of Packed FP Operations
 | A significant fraction of floating point arithmetic instructions are scalar.
 | Use Intel Advisor to see possible reasons why the code was not vectorized.
 |
    Instruction Mix
        SP FLOPs: 16.2% of uOps
            Packed: 0.0% from SP FP
                128-bit: 0.0% from SP FP
                256-bit: 0.0% from SP FP
            Scalar: 100.0% from SP FP
             | This code has floating point operations and is not vectorized.
             | Consider using Intel Advisor to vectorize the loops.
             |
        DP FLOPs: 0.0% of uOps
            Packed: 0.0% from DP FP
                128-bit: 0.0% from DP FP
                256-bit: 0.0% from DP FP
            Scalar: 0.0% from DP FP
        x87 FLOPs: 0.0% of uOps
        Non-FP: 83.8% of uOps
    FP Arith/Mem Rd Instr. Ratio: 0.611
    FP Arith/Mem Wr Instr. Ratio: 3.306
Collection and Platform Info
    Application Command Line: ./kmeans_openmp/kmeans "-n" "52" "-i" "../../data/kmeans/kdd_cup" 
    Operating System: 4.19.0-22-amd64 10.13
    Computer Name: blaise
    Result Size: 24.3 MB 
    Collection start time: 13:30:14 08/06/2023 UTC
    Collection stop time: 13:30:18 08/06/2023 UTC
    Collector Type: Driverless Perf per-process sampling
    CPU
        Name: Intel(R) Xeon(R) Processor code named Broadwell
        Frequency: 2.200 GHz 
        Logical CPU Count: 88
        Max DRAM Single-Package Bandwidth: 97.000 GB/s

If you want to skip descriptions of detected performance issues in the report,
enter: vtune -report summary -report-knob show-issues=false -r <my_result_dir>.
Alternatively, you may view the report in the csv format: vtune -report
<report_name> -format=csv.
