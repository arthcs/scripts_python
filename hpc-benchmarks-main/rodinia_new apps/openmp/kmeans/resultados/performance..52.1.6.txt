FIB: Disabled
I/O completed
num of threads = 52
number of Clusters 5
number of Attributes 34

Time for process: 2.885607
=== FIB ===
FIB - Execution Time: 3.69749 seconds
FIB - Energy: 533.76512800 Joules
FIB - EDP: 1973.58867
Elapsed Time: 3.806s
    SP GFLOPS: 2.417
    DP GFLOPS: 0.000
    x87 GFLOPS: 0.000
    CPI Rate: 8.820
     | The CPI may be too high. This could be caused by issues such as memory
     | stalls, instruction starvation, branch misprediction or long latency
     | instructions. Explore the other hardware-related metrics to identify what
     | is causing high CPI.
     |
    Average CPU Frequency: 2.809 GHz 
    Total Thread Count: 52
Effective Physical Core Utilization: 64.8% (28.529 out of 44)
 | The metric value is low, which may signal a poor physical CPU cores
 | utilization caused by:
 |     - load imbalance
 |     - threading runtime overhead
 |     - contended synchronization
 |     - thread/process underutilization
 |     - incorrect affinity that utilizes logical cores instead of physical
 |       cores
 | Explore sub-metrics to estimate the efficiency of MPI and OpenMP parallelism
 | or run the Locks and Waits analysis to identify parallel bottlenecks for
 | other parallel runtimes.
 |
    Effective Logical Core Utilization: 38.1% (33.558 out of 88)
     | The metric value is low, which may signal a poor logical CPU cores
     | utilization. Consider improving physical core utilization as the first
     | step and then look at opportunities to utilize logical cores, which in
     | some cases can improve processor throughput and overall performance of
     | multi-threaded applications.
     |
Memory Bound: 91.5% of Pipeline Slots
 | The metric value is high. This can indicate that the significant fraction of
 | execution pipeline slots could be stalled due to demand memory load and
 | stores. Use Memory Access analysis to have the metric breakdown by memory
 | hierarchy, memory bandwidth information, correlation by memory objects.
 |
    Cache Bound: 15.6% of Clockticks
    DRAM Bound: 82.3% of Clockticks
     | The metric value is high. This indicates that a significant fraction of
     | cycles could be stalled on the main memory (DRAM) because of demand loads
     | or stores.
     |
     | The code is memory bandwidth bound, which means that there are a
     | significant fraction of cycles during which the bandwidth limits of the
     | main memory are being reached and the code could stall. Review the
     | Bandwidth Utilization Histogram to estimate the scale of the issue.
     | Improve data accesses to reduce cacheline transfers from/to memory using
     | these possible techniques: 1) consume all bytes of each cacheline before
     | it is evicted (for example, reorder structure elements and split non-hot
     | ones); 2) merge compute-limited and bandwidth-limited loops; 3) use NUMA
     | optimizations on a multi-socket system.
     |
     | The code is latency bound, which means that there are a significant
     | fraction of cycles during which the code could be stalled due to main
     | memory latency. Consider optimizing data layout or using software
     | prefetches through the compiler to improve cache reuse and to reduce the
     | data fetched from the main memory.
     |
        DRAM Bandwidth Bound: 0.0% of Elapsed Time
    NUMA: % of Remote Accesses: 0.0%

    Bandwidth Utilization
    Bandwidth Domain             Platform Maximum  Observed Maximum  Average  % of Elapsed Time with High BW Utilization(%)
    ---------------------------  ----------------  ----------------  -------  ---------------------------------------------
    DRAM, GB/sec                 144                         12.200    7.921                                           0.0%
    DRAM Single-Package, GB/sec  72                          12.100    7.361                                           0.0%
    QPI Outgoing, GB/sec         68                           9.000    5.444                                           0.0%
Vectorization: 0.0% of Packed FP Operations
 | A significant fraction of floating point arithmetic instructions are scalar.
 | Use Intel Advisor to see possible reasons why the code was not vectorized.
 |
    Instruction Mix
        SP FLOPs: 24.3% of uOps
            Packed: 0.0% from SP FP
                128-bit: 0.0% from SP FP
                256-bit: 0.0% from SP FP
            Scalar: 100.0% from SP FP
             | This code has floating point operations and is not vectorized.
             | Consider using Intel Advisor to vectorize the loops.
             |
        DP FLOPs: 0.0% of uOps
            Packed: 0.0% from DP FP
                128-bit: 0.0% from DP FP
                256-bit: 0.0% from DP FP
            Scalar: 0.0% from DP FP
        x87 FLOPs: 0.0% of uOps
        Non-FP: 75.7% of uOps
    FP Arith/Mem Rd Instr. Ratio: 1.035
    FP Arith/Mem Wr Instr. Ratio: 8.251
Collection and Platform Info
    Application Command Line: ./kmeans_openmp/kmeans "-n" "52" "-i" "../../data/kmeans/kdd_cup" 
    Operating System: 4.19.0-22-amd64 10.13
    Computer Name: blaise
    Result Size: 26.6 MB 
    Collection start time: 13:27:51 08/06/2023 UTC
    Collection stop time: 13:27:55 08/06/2023 UTC
    Collector Type: Driverless Perf per-process sampling
    CPU
        Name: Intel(R) Xeon(R) Processor code named Broadwell
        Frequency: 2.200 GHz 
        Logical CPU Count: 88
        Max DRAM Single-Package Bandwidth: 72.000 GB/s

If you want to skip descriptions of detected performance issues in the report,
enter: vtune -report summary -report-knob show-issues=false -r <my_result_dir>.
Alternatively, you may view the report in the csv format: vtune -report
<report_name> -format=csv.
